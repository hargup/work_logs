29th July 2014 1:29 AM IST

Today and yesterday, basically the whole weekend I worked on the Hacker Rank's
July real data and Image Analysis challenge. There were two problem statments,
one was based on image analysis. You are given an image of a rubix cube in
which three faces are visible you have to tell if the cube is solved or
unsolved. The first idea that came to my mind was that if the cube is solved
then there will be lot less colors than there will be for the image of cube
which is solved. And that corresponds the entropy of the image, the lower the
entropy the more likely it is that it is a solved cube. 8 images of the cube
were given as a test image. The first one was solved and the rest were
unsolved. I calculated the entropy of the image after digitizing the pixel
values to bins of size 10 and declared that an image which has more entropy
than the entropy of the first image is unsolved else it is solved. Since
entropy values are calculated on one channel images, I calculated the entropy
of the image is all three channels and compared the maximum value. This fetched
me some 15 points out of hundred. In the 8 sample cases I was unable to solve 2.
Earlier when I randomly printed "solved" or "unsolved" on images I got a score
of around 7.
Then I figured out that of the sample image which was unsolved had a rather large
background which was causing it to low entropy thus it was being classified as
solved. I decided to caculate the entropy only on the part of the image which
is not part of the background. I used the otsu thresholding to sperate the
background from the foreground, and passed the foreground as np masked arrays
to the entropy cacluation function. Now I think a blob detection algorithm
should work better. Anyway the np masked arrays didn't worked out of the box in
some cases I was getting runtime error, so, I had to let go the digitizing
thing.
Calculating entropy on the masked images improved things a lot, I got a another
sample case to pass and the score improved to 53. There was a sample case which
had an unusually high entropy though it was solved. I tried to gaussian and
median filter of various sizes to reduce noise and reduce its entropy but it
didn't had a larger relative lowering in entropy. Since the sample cases are
also included in the evaluation I added it's entorpy as a special case and
marked it as solved.

I was thinking that a solved a cube should has ideally only three peaks in its
histogram removing black and white since there should be only three colors
visible. Then I began analyzing the histograms and in the process I learned to
display multiple images in IPython qtconsole with matplotlib inline option, to
do so you have to create a new figure for every iteration of the loop else the
data gets appened to the previous plot and you get only one graph. The three
peak property was obvious in 2 of the solved cubes out of 3 in samples. For one
I couldn't look at it and tell it is solved leave the progarm to do it. I tried
gaussian filter on the image but it fattened the histogram and created more
peaks. Median filter did a good by sharpening the peaks but the whole histogram
approach seems useless now.

All these approaches look at global features of the image and negelect the
spatial relation between pixels, I can try a lot of approaches in them.
One I was thinking was dilate the image so much so that there are no boundaries
of the cube left and then if there are only three colors classify it as solved,
but it is a pretty wild thought as I don't know how to do dialation on gray
scale images. I guess I first have to do clustring. I talked to Krishna about
the problem and he did a lot of hard work, implemented a blob detection algo
then counting the number of blobs with similar color et cetra

The problem was that you are given a set of data for the highest prise of the
NYSE stocks of consecutive and of then 20 values are missing you have to
predict these values. I remember hearing somewhere that stock prizes can be
approximated by random walk. I tried to do that. I caculated the mean of the differences
of the values of consecutive days(ignoring missing days). Say that value is e.
Then I random decide to add or subtract that value from the previous non
missing day and did the same for the non missing day after it and then took
their averages. There was rule for this problem that if you get runtime
error in any of the test cases the total score will then be zero.
I was getting a runtime error and the reason was that there was typo
in a variable name in the block that was handled if the value for the very
first day was missing. It looks like I have start using pylint, I just fear
that its errors will be too distracting.
When the code ran it turned to do surprizingly well compared to other peoples
code. But that was mere luck. I submitted again I got a lowere score than last
time. Then I choose a random value from the array of the absolute differences
in the values of the consequetive days but it performed worse. I gave up on the
problem for now, since there isn't much you can do and them first I have to
make a framework to judge different methods since the algos are random I need
to have a reliable way to establish one method is better than the other.
I found a program on github to download NYSE data in pandas format. I'll create
a benchmarking program for the different methods if I feel motivated enough.
